<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns#
article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Tensorflow Hints | Illarion Khlestov Blog</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.xml">
<link rel="canonical" href="https://ikhlestov.github.io/pages/machine-learning/tensorflow-hints/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: 'center', // Change this to 'center' to center equations.
});
</script><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Illarion Khlestov">
<meta property="og:site_name" content="Illarion Khlestov Blog">
<meta property="og:title" content="Tensorflow Hints">
<meta property="og:url" content="https://ikhlestov.github.io/pages/machine-learning/tensorflow-hints/">
<meta property="og:description" content="Contents:

Add logs to Summary Writer outside from graph
Handle Memory Consumption by Graph
Dynamic vs. Static RNNs
Handle last state from RNN inside graph
Run model without GPU
Change inline setting ">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2016-11-02T14:41:13Z">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ikhlestov.github.io/">

                <span id="blog-title">Illarion Khlestov Blog</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../../">Blog</a>
                </li>
<li>
<a href="../../">Pages</a>
                </li>
<li>
<a href="../../../listings/">Listings</a>
                </li>
<li>
<a href="../../../archive.html">Archive</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.rst" id="sourcelink">Source</a>
    </li>
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
<article class="post-text storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Tensorflow&nbsp;Hints</a></h1>

        
    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents:</p>
<ul class="simple">
<li><a class="reference internal" href="#add-logs-to-summary-writer-outside-from-graph" id="id1">Add logs to Summary Writer outside from&nbsp;graph</a></li>
<li><a class="reference internal" href="#handle-memory-consumption-by-graph" id="id2">Handle Memory Consumption by&nbsp;Graph</a></li>
<li><a class="reference internal" href="#dynamic-vs-static-rnns" id="id3">Dynamic vs. Static&nbsp;RNNs</a></li>
<li><a class="reference internal" href="#handle-last-state-from-rnn-inside-graph" id="id4">Handle last state from RNN inside&nbsp;graph</a></li>
<li><a class="reference internal" href="#run-model-without-gpu" id="id5">Run model without&nbsp;GPU</a></li>
<li><a class="reference internal" href="#change-inline-setting-during-training" id="id6">Change inline setting during&nbsp;training</a></li>
<li><a class="reference internal" href="#get-last-output-from-rnn" id="id7">Get last output from&nbsp;rnn</a></li>
<li><a class="reference internal" href="#batch-normalization" id="id8">Batch&nbsp;Normalization</a></li>
<li><a class="reference internal" href="#applying-weights-regularization" id="id9">Applying weights&nbsp;regularization</a></li>
<li><a class="reference internal" href="#load-part-of-graph-from-previous-run" id="id10">Load part of graph from previous&nbsp;run</a></li>
<li><a class="reference internal" href="#count-trainable-params" id="id11">Count trainable&nbsp;params</a></li>
<li><a class="reference internal" href="#handle-tensorarrays-correct-way-inside-tf-while-loop" id="id12">Handle TensorArrays correct way inside&nbsp;tf.while_loop</a></li>
<li><a class="reference internal" href="#explore-checkpoints-file" id="id13">Explore checkpoints&nbsp;file</a></li>
<li><a class="reference internal" href="#restore-part-of-the-tensor-from-saving" id="id14">Restore part of the tensor from&nbsp;saving</a></li>
<li><a class="reference internal" href="#todo" id="id15">TODO</a></li>
</ul>
</div>
<div class="section" id="add-logs-to-summary-writer-outside-from-graph">
<h2><a class="toc-backref" href="#id1">Add logs to Summary Writer outside from&nbsp;graph</a></h2>
<p>Usual we use summary writer in such&nbsp;way:</p>
<pre class="code python"><a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-1"></a><span class="c1"># inside graph definition</span>
<a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-2"></a><span class="n">tf</span><span class="o">.</span><span class="n">scalar_summary</span><span class="p">(</span><span class="s2">"some_var"</span><span class="p">,</span> <span class="n">some_var</span><span class="p">)</span>
<a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-3"></a>
<a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-4"></a><span class="c1"># inside graph execution</span>
<a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-5"></a><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-6"></a>    <span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">'logs_dir'</span><span class="p">)</span>
<a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-7"></a>    <span class="n">merged_summary</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">merge_all_summaries</span><span class="p">()</span>
<a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-8"></a>    <span class="c1"># get results from session execution</span>
<a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-9"></a>
<a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-10"></a>    <span class="n">summary</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">merged_summary</span><span class="p">)</span>
<a name="rest_code_39c838a9ffad47bcbfa52269b298ca45-11"></a>    <span class="n">summary_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">some_step</span><span class="p">)</span>
</pre>
<p>As you can see you can get only variables from the graph. But what if we want some post
processing(for example mean loss per epoch, not per batch) of just add some self generated
data? In this case we may generate <cite>summary</cite> by&nbsp;hands.</p>
<pre class="code python"><a name="rest_code_3e2c985317f84ea3ac0487d473050e83-1"></a><span class="c1"># no any definitions inside graph or session fetches.</span>
<a name="rest_code_3e2c985317f84ea3ac0487d473050e83-2"></a><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<a name="rest_code_3e2c985317f84ea3ac0487d473050e83-3"></a>    <span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">'logs_dir'</span><span class="p">)</span>
<a name="rest_code_3e2c985317f84ea3ac0487d473050e83-4"></a>    <span class="n">summary</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Summary</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span>
<a name="rest_code_3e2c985317f84ea3ac0487d473050e83-5"></a>        <span class="n">tf</span><span class="o">.</span><span class="n">Summary</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">"some_tag"</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">some_value</span><span class="p">),</span>
<a name="rest_code_3e2c985317f84ea3ac0487d473050e83-6"></a>        <span class="n">tf</span><span class="o">.</span><span class="n">Summary</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">"mean_loss"</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">mean_loss</span><span class="p">)</span>
<a name="rest_code_3e2c985317f84ea3ac0487d473050e83-7"></a>    <span class="p">])</span>
<a name="rest_code_3e2c985317f84ea3ac0487d473050e83-8"></a>    <span class="n">summary_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">some_step</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="handle-memory-consumption-by-graph">
<h2><a class="toc-backref" href="#id2">Handle Memory Consumption by&nbsp;Graph</a></h2>
<p>During training graphs on GPUs you may note that graph take all available free memory.
But what in case you have very simple model and just want to run 2 or 3 of the on GPU?
For such case you may use config inside session, that will provide to the model only required amount of memory.
More about this you may read in
<a class="reference external" href="https://www.tensorflow.org/versions/master/how_tos/using_gpu/index.html#allowing-gpu-memory-growth">tensorflow official docs</a>.</p>
<pre class="code python"><a name="rest_code_d63093b7eca24a12a3017161e3d7c6ae-1"></a><span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">()</span>
<a name="rest_code_d63093b7eca24a12a3017161e3d7c6ae-2"></a><span class="n">config</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="bp">True</span>
<a name="rest_code_d63093b7eca24a12a3017161e3d7c6ae-3"></a><span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="dynamic-vs-static-rnns">
<h2><a class="toc-backref" href="#id3">Dynamic vs. Static&nbsp;RNNs</a></h2>
<p>Just forget about static RNNs, use Dynamic for your purposes.
They are faster to build and also not required manual resizing/spliting of the input data.
Full explanation why is it so you may found
<a class="reference external" href="http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/">here</a>.</p>
<pre class="code python"><a name="rest_code_8415a1733a0448cd846015cb58caa3e0-1"></a><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">])</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-2"></a>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-3"></a><span class="c1"># usual RNN</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-4"></a><span class="n">inputs_splited</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">input_step</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-5"></a>                  <span class="k">for</span> <span class="n">input_step</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)]</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-6"></a><span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-7"></a>    <span class="n">cell</span><span class="p">,</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-8"></a>    <span class="n">inputs_splited</span><span class="p">,</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-9"></a>    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-10"></a>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-11"></a><span class="c1"># for dynamic RNN we not required reshaping</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-12"></a><span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-13"></a>    <span class="n">cell</span><span class="p">,</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-14"></a>    <span class="n">inputs</span><span class="p">,</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-15"></a>    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-16"></a><span class="c1"># if we provide data with shape num_step x batch_size</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-17"></a><span class="c1"># we can just provide time_major=True flag to dynamic RNN call</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-18"></a><span class="n">inputs_transposed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-19"></a><span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-20"></a>    <span class="n">cell</span><span class="p">,</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-21"></a>    <span class="n">inputs_transposes</span><span class="p">,</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-22"></a>    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
<a name="rest_code_8415a1733a0448cd846015cb58caa3e0-23"></a>    <span class="n">time_major</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="handle-last-state-from-rnn-inside-graph">
<h2><a class="toc-backref" href="#id4">Handle last state from RNN inside&nbsp;graph</a></h2>
<p>When using rnn usual we get last state of RNNs and send back the through feed&nbsp;dict:</p>
<pre class="code python"><a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-1"></a><span class="c1"># inside model definition</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-2"></a><span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">)</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-3"></a><span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-4"></a><span class="n">rnn_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_state_fw</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-5"></a>    <span class="n">cell</span><span class="o">=</span><span class="n">cell</span><span class="p">,</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-6"></a>    <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-7"></a>    <span class="n">initial_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span><span class="p">)</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-8"></a>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-9"></a><span class="c1"># and after during session</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-10"></a><span class="n">last_state</span> <span class="o">=</span> <span class="bp">None</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-11"></a><span class="k">if</span> <span class="n">last_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-12"></a>    <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span><span class="p">:</span> <span class="n">last_state</span><span class="p">}</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-13"></a><span class="n">_</span><span class="p">,</span> <span class="n">last_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-14"></a>    <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_state</span><span class="p">],</span>
<a name="rest_code_bf014705ad4b41a0bfd28927fb8fee4f-15"></a>    <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
</pre>
<p>But in this case we move last state from GPU memory and backwards. This is unreasonable.
We can handle last state inside GPU directly&nbsp;as:</p>
<pre class="code python"><a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-1"></a><span class="c1"># inside model definition</span>
<a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-2"></a><span class="n">last_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">]),</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-3"></a><span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">)</span>
<a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-4"></a><span class="n">rnn_out</span><span class="p">,</span> <span class="n">final_states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
<a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-5"></a>    <span class="n">cell</span><span class="o">=</span><span class="n">cell</span><span class="p">,</span>
<a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-6"></a>    <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
<a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-7"></a>    <span class="n">initial_state</span><span class="o">=</span><span class="n">last_state</span><span class="p">)</span>
<a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-8"></a>
<a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-9"></a><span class="c1"># and after to assign new value to last state we should use small trick</span>
<a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-10"></a><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">last_state</span><span class="p">,</span> <span class="n">final_states</span><span class="p">)]):</span>
<a name="rest_code_7e862e0e2a8048fd96cec52b722444b2-11"></a>    <span class="n">rnn_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">rnn_out</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="run-model-without-gpu">
<h2><a class="toc-backref" href="#id5">Run model without&nbsp;GPU</a></h2>
<p>In case you have GPUs on your machine but want to train without them, you should
just pass additional env variable <cite>CUDA_VISIBLE_DEVICES=&#8221;</cite> during script&nbsp;call.</p>
<pre class="code bash"><a name="rest_code_8679f4da50e14998913f3bd17b8d1062-1"></a>$ <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="s1">''</span> python some_model.py
</pre>
</div>
<div class="section" id="change-inline-setting-during-training">
<h2><a class="toc-backref" href="#id6">Change inline setting during&nbsp;training</a></h2>
<pre class="code python"><a name="rest_code_8bc8b92c678d4a2f9997957e93cbe370-1"></a><span class="n">x</span> <span class="o">=</span> <span class="n">some_tensor</span>
<a name="rest_code_8bc8b92c678d4a2f9997957e93cbe370-2"></a><span class="n">is_training</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[])</span>
<a name="rest_code_8bc8b92c678d4a2f9997957e93cbe370-3"></a><span class="c1"># should define as function, because under condition should be callable</span>
<a name="rest_code_8bc8b92c678d4a2f9997957e93cbe370-4"></a><span class="k">def</span> <span class="nf">apply_dropout</span><span class="p">():</span> <span class="c1"># Function to apply when training mode ON.</span>
<a name="rest_code_8bc8b92c678d4a2f9997957e93cbe370-5"></a>     <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
<a name="rest_code_8bc8b92c678d4a2f9997957e93cbe370-6"></a><span class="c1"># Only apply dropout at training time.</span>
<a name="rest_code_8bc8b92c678d4a2f9997957e93cbe370-7"></a><span class="c1"># tf.cond(cond, true_function, false_function)</span>
<a name="rest_code_8bc8b92c678d4a2f9997957e93cbe370-8"></a><span class="n">new_x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cond</span><span class="p">(</span><span class="n">is_training</span><span class="p">,</span> <span class="n">apply_dropout</span><span class="p">,</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="get-last-output-from-rnn">
<h2><a class="toc-backref" href="#id7">Get last output from&nbsp;rnn</a></h2>
<pre class="code python"><a name="rest_code_dd72d21e55094a05b6844c4702f08cbb-1"></a><span class="n">rnn_out</span><span class="p">,</span> <span class="n">last_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="o">..</span><span class="p">)</span>
<a name="rest_code_dd72d21e55094a05b6844c4702f08cbb-2"></a><span class="n">rnn_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">rnn_out</span><span class="p">,</span> <span class="p">[</span><span class="bp">False</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">False</span><span class="p">])</span>
<a name="rest_code_dd72d21e55094a05b6844c4702f08cbb-3"></a><span class="n">rnn_out_last</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">rnn_out</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre>
</div>
<div class="section" id="batch-normalization">
<h2><a class="toc-backref" href="#id8">Batch&nbsp;Normalization</a></h2>
<p>Notes based on <a class="reference external" href="https://arxiv.org/pdf/1502.03167v3.pdf">this paper</a>. I think to understood BN enough just quickly pass through 3rd paragraph.
At glance batch normalizaion helps training as the layer does not have to learn offsets in the input data, and can focus on how to best combine&nbsp;features.</p>
<p>It seems that when BN is used, such nuances should be&nbsp;considered:</p>
<p>If we have usual layer as <span class="math">\(z = g(Wu + b)\)</span>,
where <span class="math">\(g(.)\)</span> is the nonlinearity such as sigmoid or ReLU
batch normalization should be applied as
<span class="math">\(z = g(BN(Wu))\)</span>. Note that BN applied <strong>before</strong> nonlinearity.
Also due to internal shift <span class="math">\(\beta\)</span> existed in BN bias <span class="math">\(b\)</span> can be&nbsp;omitted.</p>
<p>If we apply <a class="reference external" href="https://www.tensorflow.org/api_docs/python/contrib.layers/higher_level_ops_for_building_neural_network_layers_#batch_norm">batch norm layer from tensorflow</a>
we should clear declare param <cite>is_training=True/False</cite> during training/inference. Because for training and inference different approaches used by BN.
To understood what exactly each param handled by layer mean - take a look on algorithms 1 and 2 descriptions in the <a class="reference external" href="https://arxiv.org/pdf/1502.03167v3.pdf">original paper</a> on pages 3 and 4 accordingly. Really is seems that it&#8217;s enough to use tf contrib layer with all default params only with redefined <cite>scale</cite> param. <span class="math">\(\gamma\)</span> (scale) and <span class="math">\(\beta\)</span> (shift) params will be trainable by&nbsp;default.</p>
<pre class="code python"><a name="rest_code_cebdc23dfbf64753b5b13a24a06e370a-1"></a><span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<a name="rest_code_cebdc23dfbf64753b5b13a24a06e370a-2"></a><span class="n">normed_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<a name="rest_code_cebdc23dfbf64753b5b13a24a06e370a-3"></a><span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">normed_logits</span><span class="p">)</span>
<a name="rest_code_cebdc23dfbf64753b5b13a24a06e370a-4"></a>
<a name="rest_code_cebdc23dfbf64753b5b13a24a06e370a-5"></a><span class="c1"># next lines should be added so Optimizer can find variables to optimize</span>
<a name="rest_code_cebdc23dfbf64753b5b13a24a06e370a-6"></a><span class="n">update_ops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">UPDATE_OPS</span><span class="p">)</span>
<a name="rest_code_cebdc23dfbf64753b5b13a24a06e370a-7"></a><span class="k">if</span> <span class="n">update_ops</span><span class="p">:</span>
<a name="rest_code_cebdc23dfbf64753b5b13a24a06e370a-8"></a>    <span class="n">updates</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="o">*</span><span class="n">update_ops</span><span class="p">)</span>
<a name="rest_code_cebdc23dfbf64753b5b13a24a06e370a-9"></a>    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">control_flow_ops</span><span class="o">.</span><span class="n">with_dependencies</span><span class="p">([</span><span class="n">updates</span><span class="p">],</span> <span class="n">total_loss</span><span class="p">)</span>
</pre>
<p>Maybe sometimes easier use <em>in place</em> update of alpha and beta. In docs was mentioned that this approach can be a little bit slower, but at least it less boilerplate. Also for training flag it may be conveniently to use tflearn train&nbsp;flags</p>
<pre class="code python"><a name="rest_code_9c6875507125450882a4f9a85c91d4cd-1"></a><span class="n">is_training</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[])</span>
<a name="rest_code_9c6875507125450882a4f9a85c91d4cd-2"></a>
<a name="rest_code_9c6875507125450882a4f9a85c91d4cd-3"></a><span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">(</span>
<a name="rest_code_9c6875507125450882a4f9a85c91d4cd-4"></a>    <span class="n">_input</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="n">is_training</span><span class="p">,</span>
<a name="rest_code_9c6875507125450882a4f9a85c91d4cd-5"></a>    <span class="n">updates_collections</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="applying-weights-regularization">
<h2><a class="toc-backref" href="#id9">Applying weights&nbsp;regularization</a></h2>
<pre class="code python"><a name="rest_code_6e07438a608e401a9822eba70f7be677-1"></a><span class="c1"># some usual loss definition as cross-entropy or MSE</span>
<a name="rest_code_6e07438a608e401a9822eba70f7be677-2"></a><span class="n">initial_loss</span> <span class="o">=</span> <span class="n">cross_entropy</span>
<a name="rest_code_6e07438a608e401a9822eba70f7be677-3"></a><span class="n">l2_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span>
<a name="rest_code_6e07438a608e401a9822eba70f7be677-4"></a>    <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">l2_loss</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">()])</span>
<a name="rest_code_6e07438a608e401a9822eba70f7be677-5"></a>
<a name="rest_code_6e07438a608e401a9822eba70f7be677-6"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SomeOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
<a name="rest_code_6e07438a608e401a9822eba70f7be677-7"></a><span class="c1"># now we should minimize sum of initial loss and regularization</span>
<a name="rest_code_6e07438a608e401a9822eba70f7be677-8"></a><span class="n">train_step</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span> <span class="o">+</span> <span class="n">l2_loss</span> <span class="o">*</span> <span class="n">weight_decay</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="load-part-of-graph-from-previous-run">
<h2><a class="toc-backref" href="#id10">Load part of graph from previous&nbsp;run</a></h2>
<pre class="code python"><a name="rest_code_e4be6daa314749389f054f05a32c1153-1"></a><span class="n">all_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">all_variables</span><span class="p">()</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-2"></a><span class="n">restored_scopes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Scope_1'</span><span class="p">,</span> <span class="s1">'Scope_2'</span><span class="p">]</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-3"></a><span class="c1"># get only restored variables</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-4"></a><span class="n">restored_vars</span> <span class="o">=</span> <span class="p">[</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-5"></a>    <span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span> <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'/'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">restored_scopes</span><span class="p">]</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-6"></a><span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="n">var_list</span><span class="o">=</span><span class="n">restored_vars</span><span class="p">)</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-7"></a><span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">previous_model_saves</span><span class="p">)</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-8"></a>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-9"></a><span class="c1"># now initialize all not resotred variables</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-10"></a><span class="n">initialized_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">all_vars</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">restored_vars</span><span class="p">]</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-11"></a><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">variables_initializer</span><span class="p">(</span><span class="n">initialized_vars</span><span class="p">))</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-12"></a>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-13"></a><span class="c1"># also sometimes to clarify it's better to print restored variables</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-14"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Such vars were be restored"</span><span class="p">)</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-15"></a><span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">restored_vars</span><span class="p">:</span>
<a name="rest_code_e4be6daa314749389f054f05a32c1153-16"></a>    <span class="k">print</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="count-trainable-params">
<h2><a class="toc-backref" href="#id11">Count trainable&nbsp;params</a></h2>
<pre class="code python"><a name="rest_code_1d790eb1d2484b21b982ec6563db9efb-1"></a><span class="n">total_parameters</span> <span class="o">=</span> <span class="mi">0</span>
<a name="rest_code_1d790eb1d2484b21b982ec6563db9efb-2"></a><span class="k">for</span> <span class="n">variable</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">():</span>
<a name="rest_code_1d790eb1d2484b21b982ec6563db9efb-3"></a>    <span class="n">shape</span> <span class="o">=</span> <span class="n">variable</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span>
<a name="rest_code_1d790eb1d2484b21b982ec6563db9efb-4"></a>    <span class="n">variable_parametes</span> <span class="o">=</span> <span class="mi">1</span>
<a name="rest_code_1d790eb1d2484b21b982ec6563db9efb-5"></a>    <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
<a name="rest_code_1d790eb1d2484b21b982ec6563db9efb-6"></a>        <span class="n">variable_parametes</span> <span class="o">*=</span> <span class="n">dim</span><span class="o">.</span><span class="n">value</span>
<a name="rest_code_1d790eb1d2484b21b982ec6563db9efb-7"></a>    <span class="n">total_parameters</span> <span class="o">+=</span> <span class="n">variable_parametes</span>
<a name="rest_code_1d790eb1d2484b21b982ec6563db9efb-8"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Total training params: </span><span class="si">%.5f</span><span class="s2">M"</span> <span class="o">%</span> <span class="p">(</span><span class="n">total_parameters</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">))</span>
</pre>
</div>
<div class="section" id="handle-tensorarrays-correct-way-inside-tf-while-loop">
<h2><a class="toc-backref" href="#id12">Handle TensorArrays correct way inside&nbsp;tf.while_loop</a></h2>
<p>Sometimes we want to pass output from one loop step, to next step.
For this we can use <tt class="docutils literal">tf.TensorArray</tt> with read and write operations.
But in case we read and write to same tensorarray inside loop - we should manually set number of available while loop <tt class="docutils literal">parallel_iterations=1</tt>.
This is because in case of parallel loop execution(parallel_iterations &gt; 1) some thread may try to read info from tensorArray, that was not written to it by another one thread.
Try to copy/run code snippet&nbsp;below.</p>
<pre class="code python"><a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-1"></a><span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials</span> <span class="kn">import</span> <span class="n">mnist</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-2"></a><span class="c1"># code require tensorflow verions==1.0</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-3"></a><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-4"></a>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-5"></a><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">30</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-6"></a><span class="n">BREAK_CODE</span> <span class="o">=</span> <span class="bp">True</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-7"></a><span class="k">if</span> <span class="n">BREAK_CODE</span><span class="p">:</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-8"></a>    <span class="c1"># fail with this settings</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-9"></a>    <span class="n">parallel_iterations</span> <span class="o">=</span> <span class="mi">10</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-10"></a><span class="k">else</span><span class="p">:</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-11"></a>    <span class="c1"># work as expected with this settings</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-12"></a>    <span class="n">parallel_iterations</span> <span class="o">=</span> <span class="mi">1</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-13"></a>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-14"></a><span class="n">_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-15"></a><span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-16"></a>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-17"></a><span class="n">input_array</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-18"></a><span class="n">output_array</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorArray</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-19"></a><span class="n">one_image</span> <span class="o">=</span> <span class="n">_input</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-20"></a><span class="n">input_array</span> <span class="o">=</span> <span class="n">input_array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">one_image</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-21"></a><span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s1">'W'</span><span class="p">,</span> <span class="p">[</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-22"></a>                    <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">())</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-23"></a><span class="n">W_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">"W_out"</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">784</span><span class="p">],</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-24"></a>                        <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">random_uniform_initializer</span><span class="p">())</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-25"></a>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-26"></a>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-27"></a><span class="k">def</span> <span class="nf">body</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">inp_array</span><span class="p">,</span> <span class="n">out_array</span><span class="p">):</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-28"></a>    <span class="n">local_input</span> <span class="o">=</span> <span class="n">inp_array</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-29"></a>    <span class="n">local_input_reshaped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">local_input</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-30"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">local_input_reshaped</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-31"></a>    <span class="n">out_array</span> <span class="o">=</span> <span class="n">out_array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">result</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-32"></a>    <span class="n">next_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">W_out</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-33"></a>    <span class="n">inp_array</span> <span class="o">=</span> <span class="n">inp_array</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">next_input</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-34"></a>    <span class="k">return</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inp_array</span><span class="p">,</span> <span class="n">out_array</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-35"></a>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-36"></a>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-37"></a><span class="k">def</span> <span class="nf">cond</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-38"></a>    <span class="k">return</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">batch_size</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-39"></a>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-40"></a><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">output_array</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">while_loop</span><span class="p">(</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-41"></a>    <span class="n">cond</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">input_array</span><span class="p">,</span> <span class="n">output_array</span><span class="p">],</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-42"></a>    <span class="n">parallel_iterations</span><span class="o">=</span><span class="n">parallel_iterations</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-43"></a><span class="n">results</span> <span class="o">=</span> <span class="n">output_array</span><span class="o">.</span><span class="n">stack</span><span class="p">()</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-44"></a><span class="n">results</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-45"></a>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-46"></a><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-47"></a>    <span class="n">logits</span><span class="o">=</span><span class="n">results</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">targets</span><span class="p">))</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-48"></a><span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">()</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-49"></a>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-50"></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-51"></a>    <span class="n">mnist_data</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">input_data</span><span class="o">.</span><span class="n">read_data_sets</span><span class="p">(</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-52"></a>        <span class="s2">"/tmp/MNIST_data/"</span><span class="p">,</span> <span class="n">one_hot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-53"></a>    <span class="n">steps</span> <span class="o">=</span> <span class="mi">200</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-54"></a>    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-55"></a>        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-56"></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-57"></a>            <span class="n">batch</span> <span class="o">=</span> <span class="n">mnist_data</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">next_batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-58"></a>            <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-59"></a>                <span class="n">_input</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-60"></a>                <span class="n">targets</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-61"></a>            <span class="p">}</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-62"></a>            <span class="n">fetches</span> <span class="o">=</span> <span class="p">[</span><span class="n">loss</span><span class="p">,</span> <span class="n">train_op</span><span class="p">,</span> <span class="n">results</span><span class="p">]</span>
<a name="rest_code_1176397f8a44423b8c04d5e4ec8296c2-63"></a>            <span class="n">res_loss</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">res</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="explore-checkpoints-file">
<h2><a class="toc-backref" href="#id13">Explore checkpoints&nbsp;file</a></h2>
<p>This can be done with such helper methods <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/inspect_checkpoint.py">print_tensors_in_checkpoint_file</a> and <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/pywrap_tensorflow.py">pywrap_tensorflow</a></p>
<pre class="code python"><a name="rest_code_6aae18cf06324366849fa5c64563e5b6-1"></a><span class="kn">from</span> <span class="nn">tensorflow.python.tools.inspect_checkpoint</span> <span class="kn">import</span> <span class="n">print_tensors_in_checkpoint_file</span>
<a name="rest_code_6aae18cf06324366849fa5c64563e5b6-2"></a><span class="kn">from</span> <span class="nn">tensorflow.python</span> <span class="kn">import</span> <span class="n">pywrap_tensorflow</span>
<a name="rest_code_6aae18cf06324366849fa5c64563e5b6-3"></a>
<a name="rest_code_6aae18cf06324366849fa5c64563e5b6-4"></a><span class="n">reader</span> <span class="o">=</span> <span class="n">pywrap_tensorflow</span><span class="o">.</span><span class="n">NewCheckpointReader</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<a name="rest_code_6aae18cf06324366849fa5c64563e5b6-5"></a><span class="n">var_to_shape_map</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">get_variable_to_shape_map</span><span class="p">()</span>
<a name="rest_code_6aae18cf06324366849fa5c64563e5b6-6"></a>
<a name="rest_code_6aae18cf06324366849fa5c64563e5b6-7"></a><span class="k">if</span> <span class="n">reader</span><span class="o">.</span><span class="n">has_tensor</span><span class="p">(</span><span class="s1">'a'</span><span class="p">):</span>
<a name="rest_code_6aae18cf06324366849fa5c64563e5b6-8"></a>    <span class="c1"># numpy array</span>
<a name="rest_code_6aae18cf06324366849fa5c64563e5b6-9"></a>    <span class="n">saved_tensor</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s1">'a'</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="restore-part-of-the-tensor-from-saving">
<h2><a class="toc-backref" href="#id14">Restore part of the tensor from&nbsp;saving</a></h2>
<pre class="code python"><a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-1"></a><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-2"></a>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-3"></a><span class="c1"># create some variables</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-4"></a><span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-5"></a><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">'a'</span><span class="p">)</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-6"></a><span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">'b'</span><span class="p">)</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-7"></a>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-8"></a><span class="c1"># initialize the variables and save them</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-9"></a><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InteractiveSession</span><span class="p">()</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-10"></a><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-11"></a><span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-12"></a><span class="n">tmp_checkpoint</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">"/tmp/model.ckpt"</span><span class="p">)</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-13"></a>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-14"></a><span class="c1"># get saved variable and assign it to the value</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-15"></a><span class="n">tmp_reader</span> <span class="o">=</span> <span class="n">pywrap_tensorflow</span><span class="o">.</span><span class="n">NewCheckpointReader</span><span class="p">(</span><span class="n">tmp_checkpoint</span><span class="p">)</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-16"></a><span class="n">saved_b</span> <span class="o">=</span> <span class="n">tmp_reader</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s1">'b'</span><span class="p">)</span>
<a name="rest_code_d02a0f60ddb24047bd019eedc29966b1-17"></a><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">a</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">saved_b</span><span class="p">))</span>
</pre>
</div>
<div class="section" id="todo">
<h2><a class="toc-backref" href="#id15">TODO</a></h2>
<ul class="simple">
<li>Data Readers simple&nbsp;explanation</li>
<li>tf.py_func inside data&nbsp;readers</li>
<li>Variables and Placeholders dynamic shapes inside&nbsp;graph</li>
</ul>
</div>
</div>
    </div>
    
</article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2017         <a href="mailto:ikhlestov@gmail.com">Illarion Khlestov</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>          <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script></footer>
</div>
</div>

            <script src="../../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-92406723-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>