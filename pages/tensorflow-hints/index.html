<html prefix="
og: http://ogp.me/ns#
article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<base href="https://ikhlestov.github.io/pages/tensorflow-hints/">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Tensorflow Hints | Illarion Khlestov Blog</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://ikhlestov.github.io/pages/tensorflow-hints/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: 'left', // Change this to 'center' to center equations.
});
</script><!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Illarion Khlestov">
<meta property="og:site_name" content="Illarion Khlestov Blog">
<meta property="og:title" content="Tensorflow Hints">
<meta property="og:url" content="https://ikhlestov.github.io/pages/tensorflow-hints/">
<meta property="og:description" content="Contents:

Add logs to Summary Writer outside from graph
Handle Memory Consumption by Graph
Dynamic vs. Static RNNs
Handle last state from RNN inside graph
Run model without GPU
Data Readers simple ex">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2016-11-02T14:41:13Z">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ikhlestov.github.io/">

                <span id="blog-title">Illarion Khlestov Blog</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../">Blog</a>
                </li>
<li>
<a href="../">Pages</a>
                </li>
<li>
<a href="../../listings/">Listings</a>
                </li>
<li>
<a href="../../archive.html">Archive</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.rst" id="sourcelink">Source</a>
    </li>
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
<article class="storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Tensorflow&nbsp;Hints</a></h1>

        
    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents:</p>
<ul class="simple">
<li><a class="reference internal" href="#add-logs-to-summary-writer-outside-from-graph" id="id1">Add logs to Summary Writer outside from&nbsp;graph</a></li>
<li><a class="reference internal" href="#handle-memory-consumption-by-graph" id="id2">Handle Memory Consumption by&nbsp;Graph</a></li>
<li><a class="reference internal" href="#dynamic-vs-static-rnns" id="id3">Dynamic vs. Static&nbsp;RNNs</a></li>
<li><a class="reference internal" href="#handle-last-state-from-rnn-inside-graph" id="id4">Handle last state from RNN inside&nbsp;graph</a></li>
<li><a class="reference internal" href="#run-model-without-gpu" id="id5">Run model without&nbsp;GPU</a></li>
<li><a class="reference internal" href="#data-readers-simple-explanation" id="id6">Data Readers simple&nbsp;explanation</a></li>
<li><a class="reference internal" href="#tf-py-func-inside-data-readers" id="id7">tf.py_func inside data&nbsp;readers</a></li>
<li><a class="reference internal" href="#variables-and-placeholders-dynamic-shapes-inside-graph" id="id8">Variables and Placeholders dynamic shapes inside&nbsp;graph</a></li>
</ul>
</div>
<div class="section" id="add-logs-to-summary-writer-outside-from-graph">
<h2><a class="toc-backref" href="#id1">Add logs to Summary Writer outside from&nbsp;graph</a></h2>
<p>Usual we use summary writer in such&nbsp;way:</p>
<pre class="code python"><a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-1"></a><span class="c1"># inside graph definition</span>
<a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-2"></a><span class="n">tf</span><span class="o">.</span><span class="n">scalar_summary</span><span class="p">(</span><span class="s2">"some_var"</span><span class="p">,</span> <span class="n">some_var</span><span class="p">)</span>
<a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-3"></a>
<a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-4"></a><span class="c1"># inside graph execution</span>
<a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-5"></a><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-6"></a>    <span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">'logs_dir'</span><span class="p">)</span>
<a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-7"></a>    <span class="n">merged_summary</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">merge_all_summaries</span><span class="p">()</span>
<a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-8"></a>    <span class="c1"># get results from session execution</span>
<a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-9"></a>
<a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-10"></a>    <span class="n">summary</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">merged_summary</span><span class="p">)</span>
<a name="rest_code_f0c3a6d1efb24ad29a317da7b1d8c961-11"></a>    <span class="n">summary_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">some_step</span><span class="p">)</span>
</pre>
<p>As you can see you can get only variables from the graph. But what if we want some post
processing(for example mean loss per epoch, not per batch) of just add some self generated
data? In this case we may generate <cite>summary</cite> by&nbsp;hands.</p>
<pre class="code python"><a name="rest_code_e3fa352d946743d7a988d1ea5b21f079-1"></a><span class="c1"># no any definitions inside graph or session fetches.</span>
<a name="rest_code_e3fa352d946743d7a988d1ea5b21f079-2"></a><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<a name="rest_code_e3fa352d946743d7a988d1ea5b21f079-3"></a>    <span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SummaryWriter</span><span class="p">(</span><span class="s1">'logs_dir'</span><span class="p">)</span>
<a name="rest_code_e3fa352d946743d7a988d1ea5b21f079-4"></a>    <span class="n">summary</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Summary</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span>
<a name="rest_code_e3fa352d946743d7a988d1ea5b21f079-5"></a>        <span class="n">tf</span><span class="o">.</span><span class="n">Summary</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">"some_tag"</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">some_value</span><span class="p">),</span>
<a name="rest_code_e3fa352d946743d7a988d1ea5b21f079-6"></a>        <span class="n">tf</span><span class="o">.</span><span class="n">Summary</span><span class="o">.</span><span class="n">Value</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">"mean_loss"</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="n">mean_loss</span><span class="p">)</span>
<a name="rest_code_e3fa352d946743d7a988d1ea5b21f079-7"></a>    <span class="p">])</span>
<a name="rest_code_e3fa352d946743d7a988d1ea5b21f079-8"></a>    <span class="n">summary_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary</span><span class="p">,</span> <span class="n">some_step</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="handle-memory-consumption-by-graph">
<h2><a class="toc-backref" href="#id2">Handle Memory Consumption by&nbsp;Graph</a></h2>
<p>During training graphs on GPUs you may note that graph take all available free memory.
But what in case you have very simple model and just want to run 2 or 3 of the on GPU?
For such case you may use config inside session, that will provide to the model only required amount of memory.
More about this you may read in
<a class="reference external" href="https://www.tensorflow.org/versions/master/how_tos/using_gpu/index.html#allowing-gpu-memory-growth">tensorflow official docs</a>.</p>
<pre class="code python"><a name="rest_code_e1549a8e65cc47198e7b51234bd59a34-1"></a><span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">()</span>
<a name="rest_code_e1549a8e65cc47198e7b51234bd59a34-2"></a><span class="n">config</span><span class="o">.</span><span class="n">gpu_options</span><span class="o">.</span><span class="n">allow_growth</span> <span class="o">=</span> <span class="bp">True</span>
<a name="rest_code_e1549a8e65cc47198e7b51234bd59a34-3"></a><span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="dynamic-vs-static-rnns">
<h2><a class="toc-backref" href="#id3">Dynamic vs. Static&nbsp;RNNs</a></h2>
<p>Just forget about static RNNs, use Dynamic for your purposes.
They are faster to build and also not required manual resizing/spliting of the input data.
Full explanation why is it so you may found
<a class="reference external" href="http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/">here</a>.</p>
<pre class="code python"><a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-1"></a><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">])</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-2"></a>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-3"></a><span class="c1"># usual RNN</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-4"></a><span class="n">inputs_splited</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">input_step</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-5"></a>                  <span class="k">for</span> <span class="n">input_step</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)]</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-6"></a><span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-7"></a>    <span class="n">cell</span><span class="p">,</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-8"></a>    <span class="n">inputs_splited</span><span class="p">,</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-9"></a>    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-10"></a>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-11"></a><span class="c1"># for dynamic RNN we not required reshaping</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-12"></a><span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-13"></a>    <span class="n">cell</span><span class="p">,</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-14"></a>    <span class="n">inputs</span><span class="p">,</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-15"></a>    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-16"></a><span class="c1"># if we provide data with shape num_step x batch_size</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-17"></a><span class="c1"># we can just provide time_major=True flag to dynamic RNN call</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-18"></a><span class="n">inputs_transposed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-19"></a><span class="n">outputs</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-20"></a>    <span class="n">cell</span><span class="p">,</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-21"></a>    <span class="n">inputs_transposes</span><span class="p">,</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-22"></a>    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span>
<a name="rest_code_0b9ad6f05e8f4823be10964782ce43ff-23"></a>    <span class="n">time_major</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="handle-last-state-from-rnn-inside-graph">
<h2><a class="toc-backref" href="#id4">Handle last state from RNN inside&nbsp;graph</a></h2>
<p>When using rnn usual we get last state of RNNs and send back the through feed&nbsp;dict:</p>
<pre class="code python"><a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-1"></a><span class="c1"># inside model definition</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-2"></a><span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">)</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-3"></a><span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span> <span class="o">=</span> <span class="n">cell</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-4"></a><span class="n">rnn_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_state_fw</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-5"></a>    <span class="n">cell</span><span class="o">=</span><span class="n">cell</span><span class="p">,</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-6"></a>    <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-7"></a>    <span class="n">initial_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span><span class="p">)</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-8"></a>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-9"></a><span class="c1"># and after during session</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-10"></a><span class="n">last_state</span> <span class="o">=</span> <span class="bp">None</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-11"></a><span class="k">if</span> <span class="n">last_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-12"></a>    <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">initial_state</span><span class="p">:</span> <span class="n">last_state</span><span class="p">}</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-13"></a><span class="n">_</span><span class="p">,</span> <span class="n">last_state</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-14"></a>    <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_op</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_state</span><span class="p">],</span>
<a name="rest_code_58a32524d5fc4da99c3d8e6e1326d8f4-15"></a>    <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
</pre>
<p>But in this case we move last state from GPU memory and backwards. This is unreasonable.
We can handle last state inside GPU directly&nbsp;as:</p>
<pre class="code python"><a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-1"></a><span class="c1"># inside model definition</span>
<a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-2"></a><span class="n">last_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">]),</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-3"></a><span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">num_units</span><span class="o">=</span><span class="n">n_hidden</span><span class="p">)</span>
<a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-4"></a><span class="n">rnn_out</span><span class="p">,</span> <span class="n">final_states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span>
<a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-5"></a>    <span class="n">cell</span><span class="o">=</span><span class="n">cell</span><span class="p">,</span>
<a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-6"></a>    <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
<a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-7"></a>    <span class="n">initial_state</span><span class="o">=</span><span class="n">last_state</span><span class="p">)</span>
<a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-8"></a>
<a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-9"></a><span class="c1"># and after to assign new value to last state we should use small trick</span>
<a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-10"></a><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">last_state</span><span class="p">,</span> <span class="n">final_states</span><span class="p">)]):</span>
<a name="rest_code_4469b9fe751f44ee84250bd501cb42a5-11"></a>    <span class="n">rnn_out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">rnn_out</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="run-model-without-gpu">
<h2><a class="toc-backref" href="#id5">Run model without&nbsp;GPU</a></h2>
<p>In case you have GPUs on your machine but want to train without them, you should
just pass additional env variable <cite>CUDA_VISIBLE_DEVICES=&#8221;</cite> during script&nbsp;call.</p>
<pre class="code bash"><a name="rest_code_48b523fa94cb497e98882b4c9295671a-1"></a>$ <span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="s1">''</span> python some_model.py
</pre>
</div>
<div class="section" id="data-readers-simple-explanation">
<h2><a class="toc-backref" href="#id6">Data Readers simple&nbsp;explanation</a></h2>
<p>pass</p>
</div>
<div class="section" id="tf-py-func-inside-data-readers">
<h2><a class="toc-backref" href="#id7">tf.py_func inside data&nbsp;readers</a></h2>
<p>pass</p>
</div>
<div class="section" id="variables-and-placeholders-dynamic-shapes-inside-graph">
<h2><a class="toc-backref" href="#id8">Variables and Placeholders dynamic shapes inside&nbsp;graph</a></h2>
<p>pass</p>
</div>
</div>
    </div>
    
</article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2016         <a href="mailto:ikhlestov@gmail.com">Illarion Khlestov</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>          <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script></footer>
</div>
</div>

            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>