<html prefix="
og: http://ogp.me/ns#
article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<base href="https://ikhlestov.github.io/pages/general-ml-notes/">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>General ML Notes | Illarion Khlestov Blog</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://ikhlestov.github.io/pages/general-ml-notes/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    displayAlign: 'left', // Change this to 'center' to center equations.
});
</script><!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Illarion Khlestov">
<meta property="og:site_name" content="Illarion Khlestov Blog">
<meta property="og:title" content="General ML Notes">
<meta property="og:url" content="https://ikhlestov.github.io/pages/general-ml-notes/">
<meta property="og:description" content="This notes based on Neural Networks and Deep Learning
and Coursera ML Courses. They may seems to be some way unstructured, but such structure is useful for me.

Contents:

General Approach
Part I
Part">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2016-10-02T23:00:05Z">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ikhlestov.github.io/">

                <span id="blog-title">Illarion Khlestov Blog</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../">Blog</a>
                </li>
<li>
<a href="../">Pages</a>
                </li>
<li>
<a href="../../listings/">Listings</a>
                </li>
<li>
<a href="../../archive.html">Archive</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.rst" id="sourcelink">Source</a>
    </li>
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
<article class="storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">General ML&nbsp;Notes</a></h1>

        
    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<p>This notes based on <a class="reference external" href="http://neuralnetworksanddeeplearning.com/index.html">Neural Networks and Deep Learning</a>
and <a class="reference external" href="https://www.coursera.org/learn/machine-learning">Coursera ML Courses</a>. They may seems to be some way unstructured, but such structure is useful for&nbsp;me.</p>
<div class="contents topic" id="contents">
<p class="topic-title first">Contents:</p>
<ul class="simple">
<li><a class="reference internal" href="#general-approach" id="id1">General&nbsp;Approach</a></li>
<li><a class="reference internal" href="#part-i" id="id2">Part&nbsp;I</a></li>
<li><a class="reference internal" href="#part-ii" id="id3">Part&nbsp;II</a></li>
<li><a class="reference internal" href="#evaluation-of-algorithm" id="id4">Evaluation of&nbsp;algorithm</a></li>
<li><a class="reference internal" href="#overfiting-and-underfitting" id="id5">Overfiting and&nbsp;underfitting</a></li>
<li>
<a class="reference internal" href="#various-networks-types" id="id6">Various networks types</a><ul>
<li>
<a class="reference internal" href="#convolutional-network-cnn-hyperparameters" id="id7">Convolutional Network (CNN) hyperparameters</a><ul>
<li><a class="reference internal" href="#padding" id="id8">Padding</a></li>
<li><a class="reference internal" href="#stride-size" id="id9">Stride&nbsp;Size</a></li>
<li><a class="reference internal" href="#pooling" id="id10">Pooling</a></li>
<li><a class="reference internal" href="#channels" id="id11">Channels</a></li>
</ul>
</li>
<li><a class="reference internal" href="#highway-networks" id="id12">Highway&nbsp;Networks</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="general-approach">
<h2><a class="toc-backref" href="#id1">General&nbsp;Approach</a></h2>
<ul class="simple">
<li>Define network&nbsp;architecture</li>
<li>Choose right cost&nbsp;function</li>
<li>Calculate gradient descent if&nbsp;necessary</li>
<li>Train, tune&nbsp;hyperparameters.</li>
</ul>
</div>
<div class="section" id="part-i">
<h2><a class="toc-backref" href="#id2">Part&nbsp;I</a></h2>
<p>Sigmoid&nbsp;function:</p>
<div class="math">
\begin{equation*}
\sigma(z) = \frac{1}{1 + e^{-z}}
\end{equation*}
</div>
<p><span class="math">\(\sigma(\infty)\approx 1\)</span>, <span class="math">\(\sigma(-\infty)\approx 0\)</span>,
but note, that <span class="math">\(\sigma(0)=1\)</span></p>
<p>Note: <em>sigmoid function</em> (<span class="math">\(\sigma\)</span>) == <em>logistic function</em>
so <em>sigmoid neurons</em> can be called as <em>logistic neurons</em>.</p>
<p><strong>MLP</strong> is an abbreviation for <em>multilayer&nbsp;perceptrons</em></p>
<p><em>cost</em> fucntion == <em>loss</em> function == <em>objective</em>&nbsp;function.</p>
<p><em>Quadratic cost function</em> (or <em>mean squared error</em>, or just <em>MSE</em>):</p>
<div class="math">
\begin{equation*}
C(w,b)  = \frac{1}{2n}\sum_{n}||y(x) - a||^2
\end{equation*}
</div>
<p>Here,
<em>w</em> denotes the collection of all weights in the network,
<em>b</em> all the biases,
<em>n</em> is the total number of training inputs,
<em>a</em> is the vector of outputs from the network when <em>x</em> is input,
and the sum is over all training inputs, <em>x</em>.</p>
<p>An idea of <em>stochastic gradient descent</em> is to estimate the gradient
<span class="math">\(\nabla C\)</span> by computing <span class="math">\(\nabla Cx\)</span> for a small sample of randomly chosen training inputs,
not for all inputs as usual <em>gradient descent</em> do.
For this stochastic gradient descent take small number of <em>m</em> randomly chosen training inputs.
We&#8217;ll label those random training inputs <span class="math">\(X1,X2,\ldots  ,Xm\)</span> and refer to them as a <em>mini-batch</em>.
So now gradinet can be computed&nbsp;as:</p>
<div class="math">
\begin{equation*}
\nabla C \approx \frac{1}{m}\sum_{j=1}^m \nabla C_{X_j}
\end{equation*}
</div>
</div>
<div class="section" id="part-ii">
<h2><a class="toc-backref" href="#id3">Part&nbsp;II</a></h2>
<img alt="/images/ML_notes/weights_notation.png" src="../../images/ML_notes/weights_notation.png"><p>image from <a class="reference external" href="http://neuralnetworksanddeeplearning.com/chap2.html">this&nbsp;book</a></p>
<p><em>Elementwise</em> product of the two vectors denoted as <span class="math">\(s \odot t\)</span> and can be called sometimes <em>Hadamard product</em> or <em>Schur product</em>.
Her is an&nbsp;example:</p>
<div class="math">
\begin{equation*}
\left[\begin{array}{c} 1 &#92;\ 2 \end{array}\right]
  \odot \left[\begin{array}{c} 3 &#92;\ 4\end{array} \right]
= \left[ \begin{array}{c} 1 * 3 &#92;\ 2 * 4 \end{array} \right]
= \left[ \begin{array}{c} 3 &#92;\ 8 \end{array} \right]
\end{equation*}
</div>
<p>In tensorflow you should distinguish usual matrix multiplication and hadamard&nbsp;product</p>
<pre class="code python"><a name="rest_code_6dc3eff8355145a297f24f83a0e41618-1"></a><span class="c1"># W, Q - some matrices</span>
<a name="rest_code_6dc3eff8355145a297f24f83a0e41618-2"></a>
<a name="rest_code_6dc3eff8355145a297f24f83a0e41618-3"></a><span class="c1"># matrix multiplication</span>
<a name="rest_code_6dc3eff8355145a297f24f83a0e41618-4"></a><span class="n">res</span> <span class="o">=</span> <span class="n">math_ops</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">Q</span><span class="p">)</span>
<a name="rest_code_6dc3eff8355145a297f24f83a0e41618-5"></a>
<a name="rest_code_6dc3eff8355145a297f24f83a0e41618-6"></a><span class="c1"># hadamard product</span>
<a name="rest_code_6dc3eff8355145a297f24f83a0e41618-7"></a><span class="n">res</span> <span class="o">=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">Q</span>
</pre>
</div>
<div class="section" id="evaluation-of-algorithm">
<h2><a class="toc-backref" href="#id4">Evaluation of&nbsp;algorithm</a></h2>
<p>What we should&nbsp;do:</p>
<ol class="arabic simple">
<li>Split the dataset into three portions: train set, validate set and test set, in a proportion&nbsp;3:1:1.</li>
<li>When the number of examples <em>m</em> increase, the cost <span class="math">\({J_{test}}\)</span> increases, while <span class="math">\({J_{val}}\)</span> decrease. When <em>m</em> is very large, if <span class="math">\({J_{test}}\)</span> is about equal to <span class="math">\({J_{val}}\)</span> the algorithm may suffer from large bias(underfiting), while if there is a gap between <span class="math">\({J_{test}}\)</span> and <span class="math">\({J_{val}}\)</span> the algorithm may suffer from large&nbsp;variance(overfitting).</li>
<li>To solve the problem of large bias, you may decrease <span class="math">\({\rm{\lambda }}\)</span> in regularization, while increase it for the problem of large&nbsp;variance.</li>
<li>To evaluate the performance of a classification algorithm, we can use the value: precision, recall and&nbsp;F1.</li>
</ol>
<p>Precision:</p>
<div class="math">
\begin{equation*}
\frac{{TruePositive}}{{TruePositive + FalsePositive}}
\end{equation*}
</div>
<p>Recall:</p>
<div class="math">
\begin{equation*}
\frac{{TruePositive}}{{TruePositive + FalseNegtive}}
\end{equation*}
</div>
<p>F1:</p>
<div class="math">
\begin{equation*}
\frac{{2*Recall*Precision}}{{Recall + Precision}}
\end{equation*}
</div>
</div>
<div class="section" id="overfiting-and-underfitting">
<h2><a class="toc-backref" href="#id5">Overfiting and&nbsp;underfitting</a></h2>
<p>High <strong>bias</strong> is <strong>underfitting</strong> and high <strong>variance</strong> is <strong>overfitting</strong>.</p>
<p>For understanding what exactly mean <em>Bias</em> and <em>Variance</em> you may check <a class="reference external" href="http://scott.fortmann-roe.com/docs/BiasVariance.html">this</a>
or <a class="reference external" href="http://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/">this</a>
cool&nbsp;articles.</p>
<p>Next notes based on awesome Andre Ng <a class="reference external" href="https://www.youtube.com/watch?v=F1ka6a13S9I">lecture</a></p>
<p>During training as usual you split your data on train, validation and test sets.
<em>Note:</em> You should keep your validation/test data the same for model you want to compare.
After measuring errors you can get some results.
In this case difference between <em>human error</em> (how human perform such task) and <em>train error</em> will be <strong>bias</strong>.
On the other hand, difference between <em>train error</em> and <em>validation error</em> will be <strong>variance</strong>.</p>
<object data="../../images/ML_notes/bias_variance_explanation_1.svg" style="width: 320px; height: 120px;" type="image/svg+xml">
bias_variance_explanation_1</object>
<p>In such case you should consider this&nbsp;methods</p>
<object data="../../images/ML_notes/bias_variance_workflow_1.svg" style="width: 443px; height: 402px;" type="image/svg+xml">
bias_variance_workflow_1</object>
<p>Solutions inside blue boxes should be applied as first&nbsp;approach.</p>
<p>But sometimes you may have a lot of data from one domain, but test data comes from another.
In this case validation and test data should be from the same domain.
Also you may consider get validation data also from large domain.
But it should be additional validation(say <em>train-valid</em>).
Let&#8217;s see an&nbsp;example.</p>
<object data="../../images/ML_notes/data_spliting_in_domains.svg" style="width: 473px; height: 93px;" type="image/svg+xml">
data_spliting_in_domains</object>
<p>In this case we receive another correlation between&nbsp;errors:</p>
<object data="../../images/ML_notes/bias_variance_explanation_2.svg" style="width: 453px; height: 166px;" type="image/svg+xml">
bias_variance_explanation_2</object>
<p>And solution algorithm will be a little bit more&nbsp;longer:</p>
<object data="../../images/ML_notes/bias_variance_workflow_2.svg" style="width: 443px; height: 675px;" type="image/svg+xml">
bias_variance_workflow_2</object>
</div>
<div class="section" id="various-networks-types">
<h2><a class="toc-backref" href="#id6">Various networks&nbsp;types</a></h2>
<div class="section" id="convolutional-network-cnn-hyperparameters">
<h3><a class="toc-backref" href="#id7">Convolutional Network (CNN)&nbsp;hyperparameters</a></h3>
<p>More about CNNs for NLP you may reed <a class="reference external" href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/">here</a></p>
<div class="section" id="padding">
<h4><a class="toc-backref" href="#id8">Padding</a></h4>
<p>There are two types of&nbsp;padding:</p>
<ul class="simple">
<li>
<strong>zerro-padding</strong>, also known as <strong>wide convolution</strong> - all elements that would fall outside of the matrix are taken by&nbsp;zero.</li>
<li>
<strong>narrow convolution</strong> - filters applied without&nbsp;padding.</li>
</ul>
<p>Next image give you more intuition about what&#8217;s going&nbsp;on:</p>
<div class="figure">
<a class="reference external image-reference" href="../../images/ML_notes/convolutions.png"><img alt="/images/ML_notes/convolutions.thumbnail.png" src="../../images/ML_notes/convolutions.thumbnail.png"></a>
<p class="caption"><em>Narrow vs. Wide Convolution. Filter size 5, input size 7. Source: A Convolutional Neural Network for Modelling Sentences&nbsp;(2014)</em></p>
</div>
<p>In the above, the narrow convolution yields  an output of size <span class="math">\((7-5) + 1 = 3\)</span>,
and a wide convolution an output of size <span class="math">\((7+2*4 - 5) + 1 = 11\)</span>.
More generally, the formula for the output size is
<span class="math">\(n_{out} = (n_{in} + 2 * n_{padding} - n_{filter}) +&nbsp;1\)</span></p>
</div>
<div class="section" id="stride-size">
<h4><a class="toc-backref" href="#id9">Stride&nbsp;Size</a></h4>
<p><strong>Stride size</strong> - defining how much you want to shift your filter at each step.
Mainly we see stride sizes of 1, but a larger stride size may allow you to build a model that behaves somewhat similarly to a Recursive Neural Network, i.e. looks like a&nbsp;tree.</p>
<div class="figure">
<a class="reference external image-reference" href="../../images/ML_notes/strides.png"><img alt="/images/ML_notes/strides.thumbnail.png" src="../../images/ML_notes/strides.thumbnail.png"></a>
<p class="caption">Convolution Stride Size. Left: Stride size 1. Right: Stride size 2. Source: <a class="reference external" href="http://cs231n.github.io/convolutional-networks/">http://cs231n.github.io/convolutional-networks/</a></p>
</div>
</div>
<div class="section" id="pooling">
<h4><a class="toc-backref" href="#id10">Pooling</a></h4>
<p>Pooling layers subsample output of convolutional layers. There are two types of pooling - <strong>max pooling</strong> and <strong>average pooling</strong>. You don’t necessarily need to pool over the complete matrix, you could also pool over a&nbsp;window.</p>
<div class="figure">
<a class="reference external image-reference" href="../../images/ML_notes/pooling.png"><img alt="/images/ML_notes/pooling.thumbnail.png" src="../../images/ML_notes/pooling.thumbnail.png"></a>
<p class="caption">Max pooling in CNN. Source: <a class="reference external" href="http://cs231n.github.io/convolutional-networks/#pool">http://cs231n.github.io/convolutional-networks/#pool</a></p>
</div>
</div>
<div class="section" id="channels">
<h4><a class="toc-backref" href="#id11">Channels</a></h4>
<p>Channels are different sources or representations of the data. For image it&#8217;s typically RGB(red, green, blue) channels. For NLP you could have separate channels for different embeddings of various translation of the&nbsp;sentences.</p>
</div>
</div>
<div class="section" id="highway-networks">
<h3><a class="toc-backref" href="#id12">Highway&nbsp;Networks</a></h3>
<p><strong>Highway networks</strong> -
Like LSTM networks, utilize a learnable gating mechanism to improve information flow across layers.
More simple - process previous input data to the next layer.
<a class="reference external" href="http://people.idsia.ch/~rupesh/very_deep_learning/">link to papers</a> and
<a class="reference external" href="https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa">tensorflow implementation</a>.&nbsp;Intuition:</p>
<div class="math">
\begin{equation*}
y = H (x ; W_{H} ) * T (x ; W_{T} ) + x * C (x ; W_{C} )
\end{equation*}
</div>
<p>where:</p>
<ul class="simple">
<li>
<em>T</em> is <em>transform&nbsp;gate</em>
</li>
<li>
<em>C</em> is <em>carry&nbsp;gate</em>
</li>
</ul>
<p>Gates express how much of the output is produced by transforming  the  input  and  carrying  it,  respectively.
Sometimes carry gate can be set as <span class="math">\(C = 1 - T\)</span> for&nbsp;simplicity.</p>
</div>
</div>
</div>
    </div>
    
</article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2016         <a href="mailto:ikhlestov@gmail.com">Illarion Khlestov</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>          <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script></footer>
</div>
</div>

            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>